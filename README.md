# ‚öôÔ∏è MLOPs_Assignment_Option_B: Optimizing the Development & Training Pipeline

## üìå Assignment Overview

This repository contains an optimized machine learning pipeline for classifying rock, paper, and scissors hand gestures from images. The pipeline automates **environment setup**, **data preprocessing**, and **model training**, all orchestrated through a single entry point: `run_entire_dev_pipeline.py`.

Originally limited to CPU execution with slow preprocessing and suboptimal model performance, this assignment focuses on **GPU acceleration**, **batch optimization**, and **hyperparameter tuning** to significantly improve runtime and model accuracy.

---

## üéØ Objectives

To meet the optimization goals, this project improves on the baseline pipeline by:

- ‚úÖ Reducing **total runtime** to under 1 hour  
- ‚úÖ Achieving a **model accuracy of 97% or higher**  
- ‚úÖ Ensuring full **GPU (CUDA 11.8)** utilization for preprocessing and training  
- ‚úÖ Removing bottlenecks in image preprocessing and training  
- ‚úÖ Maintaining a **modular, readable, and automated** codebase  

---
## üìÇ Project Structure

‚îú‚îÄ‚îÄ run_entire_dev_pipeline.py # üöÄ Main orchestrator script
‚îú‚îÄ‚îÄ create_virtual_env.py # üîß Virtual environment + dependency setup
‚îú‚îÄ‚îÄ setup_training.py # ‚öôÔ∏è Data setup and preprocessing entry point
‚îú‚îÄ‚îÄ train_model.py # üß† Model training script
‚îú‚îÄ‚îÄ datautils.py # üñºÔ∏è Image preprocessing (resizing, grayscale, background removal)
‚îú‚îÄ‚îÄ model_utils.py # ü§ñ Model architecture, training logic, and ONNX export
‚îú‚îÄ‚îÄ requirements.txt # üì¶ Dependency list (GPU-compatible versions)
‚îú‚îÄ‚îÄ Image_Dataset.zip # üìÅ Compressed dataset (automatically extracted)
‚îú‚îÄ‚îÄ output/ # üì§ Trained model export folder
‚îî‚îÄ‚îÄ README.md

---

## üîç Pipeline Breakdown

### üìú `run_entire_dev_pipeline.py`
Main entry point for the entire workflow. It:
- Creates the virtual environment
- Installs dependencies (GPU-compatible)
- Runs dataset extraction and preprocessing
- Triggers model training and export

### üìú `create_virtual_env.py`
- Creates a Python virtual environment dynamically  
- Installs:
  - `torch` with CUDA 11.8 support  
  - `onnxruntime-gpu`  
  - `rembg` for background removal  
- Automatically extracts `Image_Dataset.zip`  

### üìú `setup_training.py` ‚ûù `datautils.py`
- Preprocesses all input images:
  - Resize  
  - Grayscale conversion  
  - **GPU-accelerated background removal** via ONNX  
- Supports **batch processing** for improved performance  

### üìú `train_model.py` ‚ûù `model_utils.py`
- Model definition and training loop  
- Uses `torch.device("cuda")` when GPU is available  
- Improved configuration:
  - 15+ epochs  
  - Better learning rate  
  - Enhanced augmentation  
- Exports final model to `output/` in ONNX format  

---

## ‚ö° Optimizations Applied

| Area             | Before                       | After                            |
|------------------|------------------------------|----------------------------------|
| Preprocessing     | 15‚Äì20 min (CPU)              | 5‚Äì8 min (GPU, batch-optimized)   |
| Training          | 5 epochs (CPU, underfit)     | 15+ epochs (GPU-accelerated)     |
| Model Accuracy    | ~70%                         | ‚â• 97%                            |
| Total Runtime     | > 1h 15m                     | ‚è±Ô∏è < 1 hour                      |
| Automation        | CPU-only                     | Fully GPU-enabled automation     |

---

## üöÄ How to Run

### 1. Clone the Repository

git clone https://github.com/your-username/MLOPs_Assignment_Option_B.git
cd MLOPs_Assignment_Option_B

python run_entire_dev_pipeline.py

üí° This script will:

Create a new virtual environment

Install GPU-compatible dependencies

Extract and preprocess the dataset

Train the model using GPU

Export the final model to /output/model.onnx

### 2. üß™ Requirements

OS: Linux / Windows with WSL2

GPU: NVIDIA with CUDA 11.8

Python: 3.8‚Äì3.10

Disk space: ~2GB

NVIDIA drivers and nvidia-smi must be installed

### 3. üìù Assessment Criteria
Metric	Target	Weight
Preprocessing Time	Under 20 minutes	50%
Training Time	Under 20 minutes	35%
Model Accuracy	‚â• 97%	15%
‚úÖ Deliverables

üîÅ Fully automated pipeline script: run_entire_dev_pipeline.py

‚ö° Optimized preprocessing using GPU and ONNX

üéØ High-accuracy model exported to ONNX format

üìÇ output/ directory containing final model

üß© Modular Python scripts for maintainability

üìò Documentation (this README)